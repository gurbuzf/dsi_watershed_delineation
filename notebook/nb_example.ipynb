{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory of the current script to the system path\n",
    "# to enable importing modules from that directory or its subdirectories.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules and functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# Import custom modules and functions\n",
    "from src.processing import read_outlets, join_watersheds2points, load_river_network, clip_river_network, insert_watershed_info, process_watershed_points\n",
    "from src.snap_pour_point import read_flow_accumulation_tif, calculate_new_pour_point\n",
    "from src.delineator import read_drainage_direction, calculate_upstream_v2  \n",
    "from src.polygonize import raster_to_polygon, rasterize_array\n",
    "from src.file_manager import create_results_directory\n",
    "\n",
    "from configuration import OUTLETS, WATERSHEDS, MODE, FLOW_ACCUMULATION, DRAINAGE_DIRECTION, PIXEL2SEARCH, RIVERS, RESULTS, MAX_STRAHLER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TR02\n",
      "[+] Processing D02A031.\n",
      "[+] Processing D02A123.\n",
      "[+] Processing D02A173.\n",
      "TR03\n",
      "[+] Processing D03A049.\n",
      "[+] Processing D03A115.\n"
     ]
    }
   ],
   "source": [
    "create_results_directory(RESULTS)\n",
    "\n",
    "points = read_outlets(OUTLETS)\n",
    "\n",
    "if MODE == \"single\":\n",
    "\n",
    "    accum, pixel_size = read_flow_accumulation_tif(FLOW_ACCUMULATION)\n",
    "\n",
    "    drainage_direction, tif_profile, dr_dir_src = read_drainage_direction(DRAINAGE_DIRECTION)\n",
    "\n",
    "    river_vector = load_river_network(RIVERS)   \n",
    "    \n",
    "    points_new = process_watershed_points(points, accum, pixel_size, drainage_direction, dr_dir_src,\n",
    "                            tif_profile, river_vector, MAX_STRAHLER, RESULTS)\n",
    "    \n",
    "    points_new[\"change_rate[%]\"] = 100 * (points_new[\"CalculatedArea[km2]\"] - points_new[\"area[km2]\"]) / points_new[\"area[km2]\"]\n",
    "    \n",
    "elif MODE == \"partial\":\n",
    "\n",
    "    points_labelled = join_watersheds2points(points, WATERSHEDS)\n",
    "    unique_watershed_ids = points_labelled[\"Watershed_ID\"].unique()\n",
    "    points_new = pd.DataFrame()\n",
    "    for watershed in unique_watershed_ids:\n",
    "        print(f\"{watershed}\")\n",
    "        filtered_points_labelled  = points_labelled[points_labelled[\"Watershed_ID\"] == watershed]    \n",
    "        accum, pixel_size = read_flow_accumulation_tif(os.path.join(FLOW_ACCUMULATION, watershed + '.tif'))\n",
    "\n",
    "        drainage_direction, tif_profile, dr_dir_src = read_drainage_direction(os.path.join(DRAINAGE_DIRECTION, watershed + '.tif'))\n",
    "\n",
    "        river_vector = load_river_network(os.path.join(RIVERS, watershed + '.geojson'))   \n",
    "        \n",
    "        points_watershed = process_watershed_points(filtered_points_labelled, accum, pixel_size, drainage_direction, dr_dir_src,\n",
    "                                tif_profile, river_vector, MAX_STRAHLER, RESULTS) \n",
    "        \n",
    "        points_new = pd.concat([points_new, points_watershed], ignore_index=True)\n",
    "        \n",
    "    points_new[\"change_rate[%]\"] = 100 * (points_new[\"CalculatedArea[km2]\"] - points_new[\"area[km2]\"]) / points_new[\"area[km2]\"]\n",
    "try:\n",
    "    points_new.to_csv(os.path.join(RESULTS, 'report_secondRUN.csv'), encoding=\"windows-1254\")\n",
    "except UnicodeEncodeError:\n",
    "    points_new.to_csv(os.path.join(RESULTS, 'report_secondRUN.csv'), encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # Get current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Format to dd/mm/YYYY HH:SS\n",
    "    formatted_datetime = now.strftime(\"%d%m%Y_%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20092023_1554'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime(\"%d%m%Y_%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUGGING POLYGONIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_upstream_v1(drainage_direction, pour_point_coords):\n",
    "    \"\"\"\n",
    "    Calculate the upstream area based on the given drainage direction and pour point coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - drainage_direction: numpy.ndarray\n",
    "        A 2D array representing the drainage direction. Each pixel indicates the direction in which water flows.\n",
    "    - pour_point_coords: tuple (row, column)\n",
    "        The row and column indices of the pour point, which is the starting point for calculating the upstream area.\n",
    "\n",
    "    Returns:\n",
    "    - upstream_area: numpy.ndarray\n",
    "        A boolean array indicating the pixels that belong to the upstream area.\n",
    "\n",
    "    The function uses a recursive algorithm to traverse upstream from the pour point, following the drainage direction.\n",
    "    It marks the pixels that contribute flow to the pour point as part of the upstream area.\n",
    "\n",
    "    Note:\n",
    "    - The drainage direction values should follow the D8 convention (values 1 to 8 representing the eight directions).\n",
    "    - The pour point coordinates should be within the boundaries of the drainage direction array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an empty array with the same shape as the drainage direction\n",
    "    upstream_area = np.zeros_like(drainage_direction, dtype=bool)\n",
    "\n",
    "    # Get the row and column indices of the pour point\n",
    "    row, col = pour_point_coords\n",
    "\n",
    "    # Define the D8 offsets for the eight directions\n",
    "    offsets = [(0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "    # Recursive function to calculate upstream area\n",
    "    def traverse_upstream(r, c):\n",
    "        # Check if the current pixel is within the boundaries of the array\n",
    "        if r < 0 or r >= drainage_direction.shape[0] or c < 0 or c >= drainage_direction.shape[1]:\n",
    "            return\n",
    "\n",
    "        # Check if the current pixel is already marked as part of the upstream area\n",
    "        if upstream_area[r, c]:\n",
    "            return\n",
    "\n",
    "        # Mark the current pixel as part of the upstream area\n",
    "        upstream_area[r, c] = True\n",
    "\n",
    "        # Iterate over the eight directions\n",
    "        for direction in range(8):\n",
    "            # Get the offset for the corresponding direction\n",
    "            offset = offsets[direction]\n",
    "\n",
    "            # Move to the next pixel based on the offset\n",
    "            next_r = r + offset[0]\n",
    "            next_c = c + offset[1]\n",
    "\n",
    "            # Check if the next pixel drains into the current pixel\n",
    "            if next_r >= 0 and next_r < drainage_direction.shape[0] and next_c >= 0 and next_c < drainage_direction.shape[1]:\n",
    "                if (drainage_direction[next_r, next_c] - 1) % 8 == (7 + direction - 4) % 8:\n",
    "                    # Recursively traverse upstream from the next pixel\n",
    "                    traverse_upstream(next_r, next_c)\n",
    "\n",
    "    # Start traversing upstream from the pour point\n",
    "    traverse_upstream(row, col)\n",
    "\n",
    "    return upstream_area.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "@njit\n",
    "def calculate_upstream_v2(drainage_direction, pour_point_coords):\n",
    "    \"\"\"\n",
    "    Calculate the upstream area based on the given drainage direction and pour point coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - drainage_direction: numpy.ndarray\n",
    "        A 2D array representing the drainage direction. Each pixel indicates the direction in which water flows.\n",
    "    - pour_point_coords: tuple (row, column)\n",
    "        The row and column indices of the pour point, which is the starting point fo r calculating the upstream area.\n",
    "\n",
    "    Returns:\n",
    "    - upstream_area: numpy.ndarray\n",
    "        A binary array indicating the pixels that belong to the upstream area (1 for upstream, 0 for other pixels).\n",
    "\n",
    "    The function uses a stack-based iterative algorithm to traverse upstream from the pour point, following the\n",
    "    drainage direction. It marks the pixels that contribute flow to the pour point as part of the upstream area.\n",
    "\n",
    "    Note:\n",
    "    - The drainage direction values should follow the D8 convention (values 1 to 8 representing the eight directions).\n",
    "    - The pour point coordinates should be within the boundaries of the drainage direction array.\n",
    "    - The function utilizes the `numba` library's `njit` decorator for improved performance.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an empty array with the same shape as the drainage direction\n",
    "    upstream_area = np.zeros_like(drainage_direction, dtype=np.int8)\n",
    "\n",
    "    # Get the row and column indices of the pour point\n",
    "    row, col = pour_point_coords\n",
    "\n",
    "    # Define the D8 offsets for the eight directions\n",
    "    offsets = [(0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1)]\n",
    "    offsets = [(0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "    # Create a stack to store the pixel coordinates\n",
    "    stack = [(row, col)]\n",
    "\n",
    "    # Mark the pour point as part of the upstream area\n",
    "    upstream_area[row, col] = 1\n",
    "\n",
    "    # Iterate until the stack is empty\n",
    "    while stack:\n",
    "        r, c = stack.pop()\n",
    "        print(\"r, c\", r, c)\n",
    "\n",
    "        # Iterate over the eight directions\n",
    "        for direction in range(8):\n",
    "            offset = offsets[direction]\n",
    "            next_r = r + offset[0]\n",
    "            next_c = c + offset[1]\n",
    "\n",
    "            # Check if the next pixel is within the array boundaries\n",
    " \n",
    "            if 0 <= next_r < drainage_direction.shape[0] and 0 <= next_c < drainage_direction.shape[1]:\n",
    "                # if (drainage_direction[next_r, next_c] - 1) % 8 == (7 + direction - 4) % 8:\n",
    "                if (drainage_direction[next_r, next_c] - 1) % 8 == (7 + direction - 4) % 8:\n",
    "                    print(next_r, next_c)\n",
    "                    upstream_area[next_r, next_c] = 1\n",
    "                    stack.append((next_r, next_c))\n",
    "        print(\"Stack:\", len(stack))\n",
    "    return upstream_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_results_directory(RESULTS)\n",
    "\n",
    "points = read_outlets(OUTLETS)\n",
    "points_labelled = join_watersheds2points(points, WATERSHEDS)\n",
    "unique_watershed_ids = points_labelled[\"Watershed_ID\"].unique()\n",
    "points = points_labelled.copy()\n",
    "\n",
    "\n",
    "for index, row in points.iterrows():\n",
    "    \n",
    "    # if row.id == \"D25A039\":\n",
    "    if row.id == \"D25A045\": \n",
    "    # if row.id == \"D25A044\": \n",
    "        print(f\"[+] Processing {row.id}.\")   \n",
    "        # Calculate new pour point\n",
    "        new_pour_point = calculate_new_pour_point(accum, pixel_size, (row.long, row.lat), 1)\n",
    "        new_pour_point_xy = dr_dir_src.index(new_pour_point[0], new_pour_point[1])\n",
    "\n",
    "        # Extract watersheds\n",
    "        upstream_area = calculate_upstream_v2(drainage_direction, new_pour_point_xy)\n",
    "        rasterized_array = rasterize_array(upstream_area, tif_profile)\n",
    "\n",
    "        # Save polygon and line as JSON\n",
    "        subbasin = raster_to_polygon(rasterized_array, save_polygon=True, \n",
    "                                        polygon_save_path=os.path.join(RESULTS, \"watershed\", str(row.id) + \"_basin\"))\n",
    "\n",
    "        # Clip rivers\n",
    "        clipped_river_network, feedback = clip_river_network(river_vector, subbasin, \n",
    "                                                            max_strahler_order=MAX_STRAHLER, \n",
    "                                                            line_save_path=os.path.join(RESULTS, \"river\", str(row.id) + \"_river\"))\n",
    "\n",
    "        # Insert watershed delineation information into the points table\n",
    "        points_copy = insert_watershed_info(points_copy, row, new_pour_point, \n",
    "                                            subbasin[\"CalculatedArea[km2]\"][0], feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbasin.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODE = \"partial\"\n",
    "if MODE == \"partial\":\n",
    "    points_labelled = join_watersheds2points(points, WATERSHEDS)\n",
    "    unique_watershed_ids = points_labelled[\"Watershed_ID\"].unique()\n",
    "    for watershed in unique_watershed_ids[:1]:\n",
    "        filtered_points_labelled  = points_labelled[points_labelled[\"Watershed_ID\"] == watershed] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in points.iterrows():\n",
    "    print(f\"[+] Proccessing {row.id}.\")\n",
    "    # Calculate new pour point\n",
    "    new_pour_point = calculate_new_pour_point(accum, pixel_size, (row.long, row.lat), PIXEL2SEARCH)\n",
    "    new_pour_point_xy = dr_dir_src.index(new_pour_point[0], new_pour_point[1])\n",
    "    # Extract watersheds\n",
    "    upstream_area = calculate_upstream_v2(drainage_direction, new_pour_point_xy)\n",
    "    rasterized_array = rasterize_array(upstream_area, tif_profile)\n",
    "    # Save polygon and line as JSON\n",
    "    subbasin = raster_to_polygon(rasterized_array, save_polygon=True, polygon_save_path=os.path.join(RESULTS,\"watershed\", str(row.id)+\"_basin\"))\n",
    "    # Clip rivers\n",
    "\n",
    "    clipped_river_network, feedback = clip_river_network(river_vector, subbasin, max_strahler_order = MAX_STRAHLER, line_save_path=os.path.join(RESULTS,\"river\", str(row.id)+\"_river\"))\n",
    "\n",
    "    # Insert watershed delienation information into the points table\n",
    "    points_copy = insert_watershed_info(points_copy, row, new_pour_point, subbasin[\"CalculatedArea[km2]\"][0], feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_watershed_points(points, accum, pixel_size, drainage_direction, dr_dir_src,\n",
    "                            tif_profile, river_vector, MAX_STRAHLER, RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dr_dir_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_over_points():\n",
    "    for index, row in points.iterrows():\n",
    "   \n",
    "        # Calculate new pour point\n",
    "        new_pour_point = calculate_new_pour_point(accum, pixel_size, (row.long, row.lat), PIXEL2SEARCH)\n",
    "        new_pour_point_xy = dr_dir_src.index(new_pour_point[0], new_pour_point[1])\n",
    "        # Extract watersheds\n",
    "        upstream_area = calculate_upstream_v2(drainage_direction, new_pour_point_xy)\n",
    "        rasterized_array = rasterize_array(upstream_area, tif_profile)\n",
    "        # Save polygon and line as JSON\n",
    "        subbasin = raster_to_polygon(rasterized_array, save_polygon=True, polygon_save_path=os.path.join(RESULTS,\"watershed\", str(row.id)+\"_basin\"))\n",
    "        # Clip rivers\n",
    "        clipped_river_network = clip_river_network(river_vector, subbasin, max_strahler_order = MAX_STRAHLER, line_save_path=os.path.join(RESULTS,\"river\", str(row.id)+\"_river\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in points.iterrows():\n",
    "   \n",
    "    # Calculate new pour point\n",
    "    new_pour_point = calculate_new_pour_point(accum, pixel_size, (row.long, row.lat), PIXEL2SEARCH)\n",
    "    new_pour_point_xy = dr_dir_src.index(new_pour_point[0], new_pour_point[1])\n",
    "    # Extract watersheds\n",
    "    upstream_area = calculate_upstream_v2(drainage_direction, new_pour_point_xy)\n",
    "    rasterized_array = rasterize_array(upstream_area, tif_profile)\n",
    "    # Save polygon and line as JSON\n",
    "    subbasin = raster_to_polygon(rasterized_array, save_polygon=True, polygon_save_path=os.path.join(RESULTS,\"watershed\", str(row.id)+\"_basin\"))\n",
    "    # Clip rivers\n",
    "    clipped_river_network = clip_river_network(river_vector, subbasin, max_strahler_order = MAX_STRAHLER, line_save_path=os.path.join(RESULTS,\"river\", str(row.id)+\"_river\"))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_drainage_direction(drainage_direction_path, outlets=None, pour_point_coord=None):\n",
    "    \"\"\"\n",
    "    Reads the drainage direction data from a TIFF file.\n",
    "\n",
    "    Parameters:\n",
    "        drainage_direction_path (str): File path of the drainage direction TIFF.\n",
    "        outlets (geopandas.GeoDataFrame, optional): GeoDataFrame containing outlets with 'long' and 'lat' columns.\n",
    "            Each outlet's coordinates will be used as pour points to locate specific cells in the TIFF.\n",
    "        pour_point_coord (tuple, optional): Coordinates of the pour point in the format (x, y).\n",
    "            The pour point coordinates are used to locate the specific cell in the TIFF.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the drainage direction data as a NumPy array,\n",
    "               the pour point coordinates in the TIFF, and the metadata profile of the TIFF.\n",
    "\n",
    "    Notes:\n",
    "        - The function uses the rasterio library to read the TIFF file.\n",
    "        - The drainage direction data is typically represented as an array where each\n",
    "          cell represents the direction of flow.\n",
    "        - If `pour_point_coord` is provided, it is used as the pour point to locate the specific cell in the TIFF.\n",
    "        - If `outlets` is provided, each outlet's coordinates are used as pour points to locate specific cells in the TIFF.\n",
    "        - The metadata profile contains information about the TIFF such as its spatial\n",
    "          reference system, resolution, and other properties.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If both `outlets` and `pour_point_coord` are provided at the same time, or if `outlets` is not a GeoDataFrame.\n",
    "    \"\"\"\n",
    "    if outlets is not None and pour_point_coord is not None:\n",
    "        raise ValueError(\"Only one of 'outlets' or 'pour_point_coord' should be provided, not both.\")\n",
    "    if outlets is not None and (outlets.empty or outlets is None):\n",
    "        raise ValueError(\"'outlets' GeoDataFrame is empty or None.\")\n",
    "    if outlets is not None and not isinstance(outlets, gpd.GeoDataFrame):\n",
    "        raise ValueError(\"'outlets' must be a GeoDataFrame.\")\n",
    "\n",
    "    with rasterio.open(drainage_direction_path) as src:\n",
    "        drainage_direction = src.read(1)\n",
    "        profile = src.profile\n",
    "        if pour_point_coord:\n",
    "            pour_point_xy = src.index(pour_point_coord[0], pour_point_coord[1])\n",
    "            return drainage_direction, pour_point_xy, profile\n",
    "        if outlets is not None:\n",
    "            for index, row in outlets.iterrows():\n",
    "                pour_point_coord = row.long, row.lat\n",
    "                pour_point_xy = src.index(pour_point_coord[0], pour_point_coord[1])\n",
    "                outlets.loc[index, 'pour_point_x'] = int(pour_point_xy[0])\n",
    "                outlets.loc[index, 'pour_point_y'] = int(pour_point_xy[1])\n",
    "            return drainage_direction, outlets, profile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET THE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neighboring pixels to consider \n",
    "# in search of the neigboring pixel with the highest flow accumualtion\n",
    "PIXEL2SEARCH = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/flow_accumulation_TR.tif'\n",
    "coord = (28.864, 40.130) \n",
    "coord = (28.963, 40.118) \n",
    "\n",
    "data, pixel_size = read_flow_accumulation_tif(path)\n",
    "new_pour_point = calculate_new_pour_point(data, pixel_size, coord, PIXEL2SEARCH)\n",
    "print(new_pour_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drainage_direction_path = \"../data/drainage_direction_TR.tif\"\n",
    "dr_dir, tif_profile, dr_dir_src = read_drainage_direction(drainage_direction_path)\n",
    "pour_point_xy  = dr_dir_src.index(new_pour_point[0, new_pour_point[1]])\n",
    "# Calculate upstream area\n",
    "upstream_area = calculate_upstream_v2(dr_dir, pour_point_xy)\n",
    "\n",
    "rasterized_array = rasterize_array(upstream_area, tif_profile, )\n",
    "subbasin = raster_to_polygon(rasterized_array, save_polygon=False, polygon_save_path=\"output/polygon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbasin.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_id = \"TR03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_vector = load_river_network(watershed_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_river_network = clip_river_network(river_vector, subbasin, 'output/river.geojson')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = read_outlets(OUTLETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_labelled = join_watersheds2points(points, WATERSHEDS)\n",
    "unique_watershed_ids = points_labelled[\"Watershed_ID\"].unique()\n",
    "for watershed in unique_watershed_ids[:1]:\n",
    "    filtered_points_labelled  = points_labelled[points_labelled[\"Watershed_ID\"] == watershed] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for watershed in unique_watershed_ids[:1]:\n",
    "    filtered_points_labelled  = points_labelled[points_labelled[\"Watershed_ID\"] == watershed] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_points_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in filtered_points_labelled.iterrows():\n",
    "    coord = [row[\"long\"], row[\"lat\"]]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = read_outlets(OUTLETS)\n",
    "\n",
    "# if MODE == \"single\":\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_delineator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
